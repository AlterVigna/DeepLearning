{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMyIrJh8M52/eYfDzihhnjf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Object Detection : YOLO v.3\n","\n","In this part it is explored how a pre-trained YOLO v3 works making use of the module OpenCV. \n","DNN (Deep Neural Network) module was initially part of opencv_contrib repo. It has been moved to the master branch of OpenCV repo last year, giving users the ability to run inference on pre-trained deep learning models within OpenCV itself. DNN module is not meant be used for training.\n","\n","\n","\n","The source code is inspired to from a YOLO tutorial at links : <br>\n","[Tutorial](https://towardsdatascience.com/yolo-object-detection-with-opencv-and-python-21e50ac599e9)\n","[GitHub](https://github.com/arunponnusamy/object-detection-opencv)"],"metadata":{"id":"w24Hel9ItaVJ"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"4FjRCsK2WNpc","executionInfo":{"status":"ok","timestamp":1675893496542,"user_tz":-60,"elapsed":6737,"user":{"displayName":"DAVIDE VIGNA","userId":"12754214940456196028"}}},"outputs":[],"source":["#Import all the required libraries\n","\n","import os\n","import random\n","import numpy as np\n","import pickle\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","from google.colab.patches import cv2_imshow   #Necessary to print image with bounding box\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from google.colab import drive\n","import cv2"]},{"cell_type":"code","source":["# Mount drive  \n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wilQ-36bg1Zn","executionInfo":{"status":"ok","timestamp":1675808422401,"user_tz":-60,"elapsed":16699,"user":{"displayName":"DAVIDE VIGNA","userId":"12754214940456196028"}},"outputId":"a64bd585-8974-4e70-af7d-409860815b52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#Set parameters\n","\n","#Paths to get the splitted dataset\n","BASE_PATH='/content/drive/MyDrive/Vigna/'\n","DATASET_FOLDER_NAME='dataset'\n","\n","NEW_PATH=os.path.join(BASE_PATH,DATASET_FOLDER_NAME)\n","NEW_PATH_TEST=os.path.join(NEW_PATH,'test')\n","\n","OBJ_DET_PATH=BASE_PATH+'object_detection'\n","\n","CLASSES_PATH=OBJ_DET_PATH+'/classes.txt'\n","WEIGHTS_PATH=OBJ_DET_PATH+'/yolov3.weights'\n","CONFIG_PATH=OBJ_DET_PATH+'/yolov3.cfg'"],"metadata":{"id":"wYJUdLzog4j6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Get some samples in test directory"],"metadata":{"id":"Z9ryWas27qxA"}},{"cell_type":"code","source":["CLASSES=[\"dog\",\"man\",\"man-dog\",\"man-woman\",\"man-woman-dog\",\"none\",\"people\",\"woman\",\"woman-dog\"]\n","NUM_IMAGES_PER_CLASS=1"],"metadata":{"id":"XXOBlC0Qz6eE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Build a list of some representative images per class\n","test_image_path=[]\n","\n","for classs in CLASSES:\n","  test_image_path.extend([NEW_PATH_TEST+'/'+classs+'/'+path for path in os.listdir(NEW_PATH_TEST+'/'+classs+'/')[:NUM_IMAGES_PER_CLASS]])"],"metadata":{"id":"qcFDXYaIz9UT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# read class names from text file\n","classes = None\n","with open(CLASSES_PATH, 'r') as f:\n","    classes = [line.strip() for line in f.readlines()]\n","\n","# generate different colors for different classes \n","COLORS = np.random.uniform(0, 255, size=(len(classes), 3))"],"metadata":{"id":"PS_yQ_Oe_P-8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function to get the output layer names \n","# in the architecture\n","def get_output_layers(net):\n","    \n","    layer_names = net.getLayerNames()\n","    try:\n","        output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n","    except:\n","        output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n","        \n","    return output_layers\n","\n","# function to draw bounding box on the detected object with class name\n","def draw_bounding_box(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n","\n","    label = str(classes[class_id])\n","\n","    color = COLORS[class_id]\n","\n","    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n","\n","    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n"],"metadata":{"id":"dqGnzYGWlPuz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to call to execute the effective objects detection.\n","def make_object_detection(image_path):\n","  # read input image\n","  image = cv2.imread(image_path)\n","\n","  Width = image.shape[1]\n","  Height = image.shape[0]\n","  scale = 0.00392\n","\n","  # read pre-trained model and config file\n","  net = cv2.dnn.readNet(WEIGHTS_PATH, CONFIG_PATH)\n","\n","  # create input blob \n","  blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n","\n","  # set input blob for the network\n","  net.setInput(blob)\n","\n","  # run inference through the network\n","  # and gather predictions from output layers\n","  outs = net.forward(get_output_layers(net))\n","\n","  # initialization\n","  class_ids = []\n","  confidences = []\n","  boxes = []\n","  conf_threshold = 0.5\n","  nms_threshold = 0.4\n","\n","  # for each detection from each output layer \n","  # get the confidence, class id, bounding box params\n","  # and ignore weak detections (confidence < 0.5)\n","  for out in outs:\n","      for detection in out:\n","          scores = detection[5:]\n","          class_id = np.argmax(scores)\n","          confidence = scores[class_id]\n","          if confidence > 0.5:\n","              center_x = int(detection[0] * Width)\n","              center_y = int(detection[1] * Height)\n","              w = int(detection[2] * Width)\n","              h = int(detection[3] * Height)\n","              x = center_x - w / 2\n","              y = center_y - h / 2\n","              class_ids.append(class_id)\n","              confidences.append(float(confidence))\n","              boxes.append([x, y, w, h])\n","\n","  # apply non-max suppression\n","  indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n","\n","  # go through the detections remaining\n","  # after nms and draw bounding box\n","  for i in indices:\n","      try:\n","          box = boxes[i]\n","      except:\n","          i = i[0]\n","          box = boxes[i]\n","      x = box[0]\n","      y = box[1]\n","      w = box[2]\n","      h = box[3]\n","      \n","      draw_bounding_box(image, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n","  \n","  # display output image    \n","  #cv2.imshow(\"object detection\", image)\n","  cv2_imshow(image)\n","\n","  # release resources\n","  cv2.destroyAllWindows()"],"metadata":{"id":"YolWjYX6lhFJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Apply Object Detection on the limited set considered"],"metadata":{"id":"lHIN20z5A7q4"}},{"cell_type":"code","source":["for imagePath in test_image_path:\n","  index=test_image_path.index(imagePath)\n","  print (\"Object detection in sample class '\"+ CLASSES[int((index/NUM_IMAGES_PER_CLASS))]+\"': \")\n","  make_object_detection(imagePath)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1JYFai1RF5sws9z-cEpq29KpxetmeOYCS"},"id":"hSkW9Bnm_zM4","executionInfo":{"status":"ok","timestamp":1675812084329,"user_tz":-60,"elapsed":25287,"user":{"displayName":"DAVIDE VIGNA","userId":"12754214940456196028"}},"outputId":"015c26aa-b059-49f8-b4b0-cfe246a8f77e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}